{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd3e048a940>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd3aebe1e48>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fd3aebe1f60>)\n"
     ]
    }
   ],
   "source": [
    "print(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ToDo\n",
    "# Make a Convnet.\n",
    "# Run The Input/output. Thats it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_convolution_layer(layer_input, weights_input_output, bias, strides, padding):\n",
    "    output = tf.nn.conv2d(layer_input, weights_input_output, strides, padding)\n",
    "    output = tf.nn.bias_add(output, bias)\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "def run_max_pool_layer(layer_input, pool_size, strides):\n",
    "    return tf.nn.max_pool(layer_input, pool_size, strides, padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[None, 108670.08]\n",
      "[None, 63364.52]\n",
      "[None, 47270.281]\n",
      "[None, 38776.359]\n",
      "[None, 29512.455]\n",
      "[None, 25485.279]\n",
      "[None, 22728.582]\n",
      "[None, 21616.66]\n",
      "[None, 18842.031]\n",
      "[None, 17123.812]\n",
      "[None, 17077.143]\n",
      "[None, 16085.091]\n",
      "[None, 12782.957]\n",
      "[None, 15540.329]\n",
      "[None, 12914.571]\n",
      "[None, 13761.687]\n",
      "[None, 11163.38]\n",
      "[None, 9826.4287]\n",
      "[None, 11167.21]\n",
      "[None, 10211.981]\n",
      "[None, 8965.7246]\n",
      "[None, 8777.8672]\n",
      "[None, 8909.627]\n",
      "[None, 8383.2959]\n",
      "[None, 7241.998]\n",
      "[None, 6528.3389]\n",
      "[None, 7068.6738]\n",
      "[None, 7440.9292]\n",
      "[None, 6317.248]\n",
      "[None, 5609.5073]\n",
      "[None, 5572.9043]\n",
      "[None, 4950.9263]\n",
      "[None, 5132.626]\n",
      "[None, 5264.2046]\n",
      "[None, 5175.6182]\n",
      "[None, 4530.4126]\n",
      "[None, 5063.8545]\n",
      "[None, 4468.168]\n",
      "[None, 5085.1191]\n",
      "[None, 4209.2949]\n",
      "[None, 4350.3789]\n",
      "[None, 4858.4224]\n",
      "[None, 3778.095]\n",
      "[None, 4360.3281]\n",
      "[None, 4033.02]\n",
      "[None, 4000.5581]\n",
      "[None, 4144.5654]\n",
      "[None, 3589.6631]\n",
      "[None, 3525.7769]\n",
      "[None, 2956.8494]\n",
      "[None, 2827.8125]\n",
      "[None, 2831.3115]\n",
      "[None, 2741.1191]\n",
      "[None, 2915.3562]\n",
      "[None, 2950.3877]\n",
      "[None, 2887.0269]\n",
      "[None, 2923.3516]\n",
      "[None, 2856.843]\n",
      "[None, 2586.0847]\n",
      "[None, 2722.1606]\n",
      "[None, 2623.4795]\n",
      "[None, 2661.1912]\n",
      "[None, 2807.1956]\n",
      "[None, 3065.4053]\n",
      "[None, 2296.0786]\n",
      "[None, 2486.145]\n",
      "[None, 2420.2698]\n",
      "[None, 2130.2029]\n",
      "[None, 2204.575]\n",
      "[None, 2004.0671]\n",
      "[None, 2249.3306]\n",
      "[None, 1824.0046]\n",
      "[None, 2064.4905]\n",
      "[None, 1972.3337]\n",
      "[None, 2026.5981]\n",
      "[None, 2015.5281]\n",
      "[None, 1839.9723]\n",
      "[None, 1703.9688]\n",
      "[None, 1854.2528]\n",
      "[None, 1920.5884]\n",
      "[None, 1607.9047]\n",
      "[None, 1863.2454]\n",
      "[None, 1714.5715]\n",
      "[None, 1948.016]\n",
      "[None, 1608.2621]\n",
      "[None, 1764.1821]\n",
      "[None, 1441.7616]\n",
      "[None, 1818.6531]\n",
      "[None, 1513.8906]\n",
      "[None, 1667.0366]\n",
      "[None, 1518.8768]\n",
      "[None, 1542.5878]\n",
      "[None, 1592.2368]\n",
      "[None, 1743.0856]\n",
      "[None, 1271.7823]\n",
      "[None, 1209.5927]\n",
      "[None, 1284.3967]\n",
      "[None, 1477.6997]\n",
      "[None, 1377.705]\n",
      "[None, 1348.3538]\n",
      "[None, 1156.0475]\n",
      "[None, 1286.1879]\n",
      "[None, 1352.9609]\n",
      "[None, 1249.8834]\n",
      "[None, 1345.8306]\n",
      "[None, 1088.2223]\n",
      "[None, 1149.8896]\n",
      "[None, 1305.3695]\n",
      "[None, 1028.3643]\n",
      "[None, 1166.2462]\n",
      "[None, 1198.5278]\n",
      "[None, 1017.9561]\n",
      "[None, 1058.1919]\n",
      "[None, 1075.4607]\n",
      "[None, 954.76843]\n",
      "[None, 925.43811]\n",
      "[None, 966.98987]\n",
      "[None, 981.99829]\n",
      "[None, 1100.6062]\n",
      "[None, 998.47467]\n",
      "[None, 1026.4136]\n",
      "[None, 1003.3122]\n",
      "[None, 880.14667]\n",
      "[None, 909.38062]\n",
      "[None, 877.22766]\n",
      "[None, 958.26154]\n",
      "[None, 763.1001]\n",
      "[None, 897.99469]\n",
      "[None, 898.97241]\n",
      "[None, 762.88086]\n",
      "[None, 714.69299]\n",
      "[None, 783.3075]\n",
      "[None, 739.6897]\n",
      "[None, 775.72144]\n",
      "[None, 823.82233]\n",
      "[None, 901.53912]\n",
      "[None, 784.73688]\n",
      "[None, 697.79401]\n",
      "[None, 661.87756]\n",
      "[None, 650.02759]\n",
      "[None, 672.53015]\n",
      "[None, 792.80975]\n",
      "[None, 703.01782]\n",
      "[None, 642.78662]\n",
      "[None, 600.88385]\n",
      "[None, 624.0097]\n",
      "[None, 610.13843]\n",
      "[None, 597.18542]\n",
      "[None, 671.89532]\n",
      "[None, 661.42078]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = .0001\n",
    "batch_size = 200\n",
    "epochs = 5\n",
    "\n",
    "# Place Holders\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Variables\n",
    "weights = {\n",
    "            \"first_layer\":tf.Variable(tf.random_normal((5, 5, 1, 32), dtype=tf.float32)),\n",
    "            \"second_layer\":tf.Variable(tf.random_normal((5, 5, 32, 64), dtype=tf.float32)),\n",
    "            \"full_layer_1\":tf.Variable(tf.random_normal((7*7*64, 1024), dtype=tf.float32)),\n",
    "            \"output_layer\":tf.Variable(tf.random_normal((1024, 10), dtype=tf.float32))\n",
    "          }\n",
    "biases = {\n",
    "            \"first_layer\":tf.Variable(tf.zeros([32], dtype=tf.float32)),\n",
    "            \"second_layer\":tf.Variable(tf.zeros([64], dtype=tf.float32)),\n",
    "            \"full_layer_1\":tf.Variable(tf.zeros([1, 1024], dtype=tf.float32)),\n",
    "            \"output_layer\":tf.Variable(tf.zeros([1, 10], dtype=tf.float32))\n",
    "        }\n",
    "\n",
    "conv1 = run_convolution_layer(x, weights[\"first_layer\"], biases[\"first_layer\"], [1, 1, 1, 1], 'SAME')\n",
    "conv1 = run_max_pool_layer(conv1, [1, 2, 2, 1], [1, 2, 2, 1])\n",
    "\n",
    "conv2 = run_convolution_layer(conv1, weights[\"second_layer\"], biases[\"second_layer\"], [1, 1, 1, 1], 'SAME')\n",
    "conv2 = run_max_pool_layer(conv2, [1, 2, 2 ,1], [1, 2, 2, 1])\n",
    "\n",
    "full_input_1 = tf.reshape(conv2, [-1, weights[\"full_layer_1\"].get_shape().as_list()[0]])\n",
    "full_output_1 = tf.nn.relu(tf.add(tf.matmul(full_input_1, weights[\"full_layer_1\"]), biases[\"full_layer_1\"]))\n",
    "full_output_1 = tf.nn.dropout(full_output_1, keep_prob)\n",
    "\n",
    "output = tf.add(tf.matmul(full_output_1, weights[\"output_layer\"]) , biases[\"output_layer\"])\n",
    "\n",
    "error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.arg_max(output, 1), tf.arg_max(y, 1)), tf.float32))\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    maximum_quantity = 30000\n",
    "#     maximum_quantity = mnist.train.images.shape[0]\n",
    "    \n",
    "    num_of_iterations = int((maximum_quantity/batch_size))\n",
    "    \n",
    "    for every_epoch in range(epochs):\n",
    "        print(str(every_epoch))\n",
    "        for i in range(num_of_iterations):\n",
    "            print(session.run([optimizer, error], feed_dict={x:mnist.train.images[i * batch_size:(i * batch_size) + batch_size, :], y:mnist.train.labels[i * batch_size:(i * batch_size) + batch_size, :], keep_prob:0.5}))\n",
    "        print(session.run([accuracy], feed_dict={x:mnist.test.images[:300, :], y:mnist.test.labels[:300, :], keep_prob:1.0}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mnist.train.labels[:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
